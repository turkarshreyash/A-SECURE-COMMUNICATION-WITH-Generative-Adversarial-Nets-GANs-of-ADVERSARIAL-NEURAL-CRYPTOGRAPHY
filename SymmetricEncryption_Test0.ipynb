{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SymmetricEncryption_Test0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuOKHK2zMuQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0129ae64-7bdd-4d5c-8ac9-318bbe979c66"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "import math\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pfAJE4ONhR_"
      },
      "source": [
        "learning_rate   = 0.0008\n",
        "batch_size      = 4096\n",
        "sample_size     = 4096 # 4096 according to the paper\n",
        "epochs          = 3000  # 850000 according to the paper\n",
        "steps_per_epoch = int(sample_size/batch_size)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPjuo61FNxP_"
      },
      "source": [
        "# BOB_LOSS_THRESH = 0.02  # Exit when Bob loss < 0.02 and Eve > 7.7 bits\n",
        "# EVE_LOSS_THRESH = 7.7"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wufzlX4IN1H_"
      },
      "source": [
        "# Input and output configuration.\n",
        "TEXT_SIZE = 16\n",
        "KEY_SIZE  = 16"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogd4JZzJOC-N"
      },
      "source": [
        "# Training parameters.\n",
        "ITERS_PER_ACTOR = 1\n",
        "EVE_MULTIPLIER = 10  # Train Eve 2x for every step of Alice/Bob"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2zqSLx1OIdR"
      },
      "source": [
        "# Set a random seed to help reproduce the output\n",
        "seed = 7919\n",
        "tf.set_random_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# False if we want to train from scratch and true to contiune training a already trained model\n",
        "restore_trained_model = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSV1fdVKOUJn"
      },
      "source": [
        "def random_bools(sample_size, n):\n",
        "\n",
        "  temp =  np.random.random_integers(0, high=1, size=[sample_size, n])\n",
        "  temp = temp*2 - 1\n",
        "  return temp.astype(np.float32)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkrp97tTOqRN"
      },
      "source": [
        "# Function to create individual models for Alice, Bob and Eve.\n",
        "def model(collection, message, key=None):\n",
        "  \n",
        "  if key is not None:\n",
        "    # if there is a key then it's either Alice or Bob model trying to encrypt and decrypt resp\n",
        "    # message and key is concatenated into single tensor and fed as an input\n",
        "    combined_input = tf.concat(axis=1, values=[message, key])\n",
        "  else:\n",
        "    # if no key is present then it's Eve model trying to eavesdrop hence pass the message as input tensor \n",
        "    combined_input = message\n",
        "\n",
        "  # collection arg is to denote the scope of model which is used to aggregate the \n",
        "  # tensor to make sure all tensor which needs to be trained are inside one scope\n",
        "  with tf.variable_scope(collection):\n",
        "    \n",
        "    \n",
        "    ## Fully connected layer of 16+16 = 32 neurons\n",
        "    fc = tf.layers.dense(combined_input, TEXT_SIZE + KEY_SIZE, activation=tf.nn.relu)\n",
        "    fc = tf.expand_dims(fc, 2)\n",
        "\n",
        "    ## Convolution Layers - Sigmoid activation function\n",
        "\n",
        "    # input: (32,1) -> output:(32,1) because filter is 1 which creates 1 channels\n",
        "    conv1 = tf.layers.conv1d( fc,    filters=1, kernel_size=4, strides= 1, padding='SAME',  activation=tf.nn.leaky_relu)\n",
        "\n",
        "    # input: (32,1) -> output:(16,2) because stride is 2 hence result is halved ( i.e 32/2 )\n",
        "    # filter is 2 which creates 2 channels\n",
        "    conv2 = tf.layers.conv1d( conv1, filters=2, kernel_size=2, strides= 2, padding='VALID', activation=tf.nn.leaky_relu)\n",
        "\n",
        "    # input: (16,2) -> output:(16,1) \n",
        "    conv3 = tf.layers.conv1d( conv2, filters=1, kernel_size=1, strides= 1, padding='SAME',  activation=tf.nn.leaky_relu)\n",
        "\n",
        "    # input: (16,1 ) -> output:(16,4) because filter is 4 which creates 4 channels\n",
        "    conv4 = tf.layers.conv1d( conv3, filters=4, kernel_size=1, strides= 1, padding='SAME',  activation=tf.nn.sigmoid)\n",
        "    \n",
        "    # input: (16,4) -> output:(16,1) because filter is 1 which creates 1 channels\n",
        "    conv5 = tf.layers.conv1d( conv4, filters=1, kernel_size=1, strides= 1, padding='SAME',  activation=tf.nn.relu)\n",
        "\n",
        "\n",
        "    ## Convolution Layers - Tanh activation function\n",
        "\n",
        "    # # input: (16,1) -> output:(16,1) because filter is 1 which creates 1 channel\n",
        "    conv6 = tf.layers.conv1d( conv5, filters=1, kernel_size=1, strides=1, padding='SAME', activation=tf.nn.tanh)\n",
        "\n",
        "    # Opposite of expand_dims function, here (16,1) tensor is converted to tensor of (16)\n",
        "    out = tf.squeeze(conv6, 2)\n",
        "\n",
        "  return out\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJkKgKwxOxJu"
      },
      "source": [
        "#alice settings\n",
        "Alice_input_message  = tf.placeholder(tf.float32, shape=(batch_size, TEXT_SIZE), name='Alice_input_message')\n",
        "Alice_input_key      = tf.placeholder(tf.float32, shape=(batch_size, KEY_SIZE), name='Alice_input_key')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhZbMUQQPDz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c282fe2-d6e2-43e3-d254-e59014a669b6"
      },
      "source": [
        "#Defined models\n",
        "Alice_out_cipher = model('Alice', Alice_input_message, Alice_input_key)\n",
        "Bob_out_message  = model('Bob', Alice_out_cipher, Alice_input_key)\n",
        "Eve_out_message  = model('Eve', Alice_out_cipher)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-0c07e3c0465d>:18: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-8-0c07e3c0465d>:24: conv1d (from tensorflow.python.keras.legacy_tf_layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB_GFq8mPvQP"
      },
      "source": [
        "## Eves LOSS\n",
        "Eves_loss = (1/batch_size)*tf.reduce_sum( tf.abs( Eve_out_message - Alice_input_message ))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otctVBnHP0ZC"
      },
      "source": [
        "## ALICE AND BOB LOSS\n",
        "Bob_loss = (1/batch_size)*tf.reduce_sum( tf.abs( Bob_out_message  - Alice_input_message ))\n",
        "Eve_evadropping_loss = tf.reduce_sum( tf.square(float(TEXT_SIZE) / 2.0 - Eves_loss) / ((TEXT_SIZE / 2)**2) )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17fHZqIxP3tR"
      },
      "source": [
        "Alice_bob_loss = Bob_loss + Eve_evadropping_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8eF7wvpP50q"
      },
      "source": [
        "# Get tensors to train\n",
        "Alice_vars =  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='Alice') \n",
        "Bob_vars   =  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='Bob') \n",
        "Eve_vars   =  tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Eve') "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWas3po_P8Uj"
      },
      "source": [
        "Eve_opt  = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, epsilon=1e-08).minimize(Eves_loss, var_list=[Eve_vars])\n",
        "bob_opt  = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, epsilon=1e-08).minimize(Alice_bob_loss, var_list=[Alice_vars + Bob_vars])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRox9W64P_FQ"
      },
      "source": [
        "sess = tf.Session() \n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwbQa1EuQBLO"
      },
      "source": [
        "alice_saver = tf.train.Saver(Alice_vars)\n",
        "bob_saver   = tf.train.Saver(Bob_vars)\n",
        "eve_saver   = tf.train.Saver(Eve_vars)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl5i0jFNQD_S"
      },
      "source": [
        "if restore_trained_model:\n",
        "  alice_saver.restore(sess, \"alice_weights.ckpt\")\n",
        "  bob_saver.restore(sess, \"bob_weights.ckpt\")\n",
        "  eve_saver.restore(sess, \"eve_weights.ckpt\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tefwo-ZEQTIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1db003-9ade-497b-ae97-90f695af7be3"
      },
      "source": [
        "# DATASET \n",
        "messages = random_bools(sample_size, TEXT_SIZE)\n",
        "keys     = random_bools(sample_size, KEY_SIZE)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iODK66Ry-Vv"
      },
      "source": [
        "epochs_list = []\n",
        "alice_bob_loss = []\n",
        "eve_evs_loss = []\n",
        "eve_loss = []"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27qyNXJLQVIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f899b2-4694-4366-f36d-d9302b835a7e"
      },
      "source": [
        "# Training begins\n",
        "for i in range(epochs):\n",
        "\n",
        "  for j in range(steps_per_epoch):\n",
        "\n",
        "    # get batch dataset to train\n",
        "    batch_messages = messages[j*batch_size: (j+1)*batch_size]\n",
        "    batch_keys     = keys[j*batch_size: (j+1)*batch_size]\n",
        "\n",
        "    # Train Alice and Bob\n",
        "    for _ in range(ITERS_PER_ACTOR):\n",
        "      temp = sess.run([bob_opt, Bob_loss, Eve_evadropping_loss, Bob_out_message],feed_dict={Alice_input_message:batch_messages , Alice_input_key:batch_keys })\n",
        "      \n",
        "      temp_alice_bob_loss = temp[1]\n",
        "      temp_eve_evs_loss   = temp[2]\n",
        "      temp_bob_msg        = temp[3]\n",
        "\n",
        "    # train Eve\n",
        "    for _ in range(ITERS_PER_ACTOR*EVE_MULTIPLIER):\n",
        "      temp = sess.run([Eve_opt, Eves_loss, Eve_out_message], feed_dict={Alice_input_message:batch_messages , Alice_input_key:batch_keys })\n",
        "\n",
        "      temp_eve_loss = temp[1]\n",
        "      temp_eve_msg  = temp[2]\n",
        "\n",
        "  # save after every 500 epochs\n",
        "  if i%500 == 0 and i!=0:\n",
        "    alice_saver.save(sess, \"alice_weights.ckpt\")\n",
        "    bob_saver.save(sess, \"bob_weights.ckpt\")\n",
        "    eve_saver.save(sess, \"eve_weights.ckpt\")\n",
        "\n",
        "\n",
        "  # output bit error and loss after every 100 epochs\n",
        "  if i%50 == 0:\n",
        "    epochs_list.append(i)\n",
        "    alice_bob_loss.append(temp_alice_bob_loss)\n",
        "    eve_evs_loss.append(temp_eve_evs_loss)\n",
        "    eve_loss.append(temp_eve_loss)\n",
        "    print('  epochs: ', i, '  bob bit error: ', temp_alice_bob_loss,' + ', temp_eve_evs_loss,'   & eve bit error:', temp_eve_loss)\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  epochs:  0   bob bit error:  15.943176  +  1.0019789    & eve bit error: 16.00439\n",
            "  epochs:  50   bob bit error:  15.930668  +  0.9926027    & eve bit error: 15.969902\n",
            "  epochs:  100   bob bit error:  15.889614  +  0.98764396    & eve bit error: 15.950154\n",
            "  epochs:  150   bob bit error:  15.41131  +  0.984824    & eve bit error: 15.938914\n",
            "  epochs:  200   bob bit error:  13.484682  +  0.98321533    & eve bit error: 15.932491\n",
            "  epochs:  250   bob bit error:  11.370431  +  0.98224723    & eve bit error: 15.928616\n",
            "  epochs:  300   bob bit error:  9.224936  +  0.9816292    & eve bit error: 15.92614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpXeiizUSkwh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOG_F8d7cfT6"
      },
      "source": [
        "import pickle\n",
        "pickle_out = open(\"epochs_list2.pickle\",\"wb\")\n",
        "pickle.dump(epochs_list, pickle_out)\n",
        "pickle_out.close()\n",
        "pickle_out = open(\"alice_bob_loss2.pickle\",\"wb\")\n",
        "pickle.dump(alice_bob_loss, pickle_out)\n",
        "pickle_out.close()\n",
        "pickle_out = open(\"eve_evs_loss2.pickle\",\"wb\")\n",
        "pickle.dump(eve_evs_loss, pickle_out)\n",
        "pickle_out.close()\n",
        "pickle_out = open(\"eve_loss2.pickle\",\"wb\")\n",
        "pickle.dump(eve_loss, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRnNnaezn0YP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0t-dXJjckSC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg7pI5E6c2kI"
      },
      "source": [
        "# import pickle\n",
        "# pickle_in = open(\"epochs_list2.pickle\",\"rb\")\n",
        "# pickle.load(epochs_list, pickle_in)\n",
        "# pickle_in.close()\n",
        "# pickle_in = open(\"alice_bob_loss2.pickle\",\"rb\")\n",
        "# pickle.load(alice_bob_loss, pickle_in)\n",
        "# pickle_in.close()\n",
        "# pickle_in = open(\"eve_evs_loss2.pickle\",\"rb\")\n",
        "# pickle.load(eve_evs_loss, pickle_in)\n",
        "# pickle_in.close()\n",
        "# pickle_in = open(\"eve_loss2.pickle\",\"rb\")\n",
        "# pickle.load(eve_loss, pickle_in)\n",
        "# pickle_in.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-ql9YkFc5lQ"
      },
      "source": [
        "offset = 0\n",
        "jump=1\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import EventCollection\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(epochs_list[offset::jump], alice_bob_loss[offset::jump], label=\"alice_bob_loss\")\n",
        "#ax.plot(epochs_list, eve_evs_loss, label=\"eve_evs_loss\")\n",
        "ax.plot(epochs_list[offset::jump], eve_loss[offset::jump], label=\"eve_loss\")\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfhjIdsGd7u5"
      },
      "source": [
        "epochs_list[100:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doy0qyEteAnp"
      },
      "source": [
        "a = \"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}